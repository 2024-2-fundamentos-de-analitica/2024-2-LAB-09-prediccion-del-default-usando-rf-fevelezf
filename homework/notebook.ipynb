{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "import gzip\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "train_df = pd.read_csv('../files/input/train_data.csv/train_default_of_credit_card_clients.csv')\n",
    "test_df = pd.read_csv('../files/input/test_data.csv/test_default_of_credit_card_clients.csv')\n",
    "\n",
    "# Renombrar la columna \"default payment next month\" a \"default\"\n",
    "train_df.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
    "test_df.rename(columns={'default payment next month': 'default'}, inplace=True)\n",
    "\n",
    "# Remover la columna \"ID\"\n",
    "train_df.drop(columns=['ID'], inplace=True)\n",
    "test_df.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "# Eliminar registros con información no disponible\n",
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "# Agrupar valores de EDUCATION > 4 en la categoría \"others\"\n",
    "train_df['EDUCATION'] = train_df['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "test_df['EDUCATION'] = test_df['EDUCATION'].apply(lambda x: 4 if x > 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "x_train = train_df.drop(columns=['default'])\n",
    "y_train = train_df['default']\n",
    "x_test = test_df.drop(columns=['default'])\n",
    "y_test = test_df['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un pipeline para el modelo de clasificación\n",
    "# Definir las columnas categóricas\n",
    "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "\n",
    "# Crear un transformador para las variables categóricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los hiperparámetros a optimizar\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='balanced_accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('preprocessor',\n",
      "                                        ColumnTransformer(remainder='passthrough',\n",
      "                                                          transformers=[('cat',\n",
      "                                                                         OneHotEncoder(),\n",
      "                                                                         ['SEX',\n",
      "                                                                          'EDUCATION',\n",
      "                                                                          'MARRIAGE'])])),\n",
      "                                       ('classifier',\n",
      "                                        RandomForestClassifier(random_state=42))]),\n",
      "             param_grid={'classifier__max_depth': [None, 10, 20],\n",
      "                         'classifier__min_samples_leaf': [1, 2],\n",
      "                         'classifier__min_samples_split': [2, 5],\n",
      "                         'classifier__n_estimators': [100, 200]},\n",
      "             scoring='balanced_accuracy')\n"
     ]
    }
   ],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo comprimido\n",
    "with gzip.open('../files/models/model.pkl.gz', 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predecir en los conjuntos de entrenamiento y prueba\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "\n",
    "# Calcular las métricas\n",
    "train_metrics = {\n",
    "    'type': 'metrics',\n",
    "    'dataset': 'train',\n",
    "    'precision': precision_score(y_train, y_train_pred),\n",
    "    'balanced_accuracy': balanced_accuracy_score(y_train, y_train_pred),\n",
    "    'recall': recall_score(y_train, y_train_pred),\n",
    "    'f1_score': f1_score(y_train, y_train_pred)\n",
    "}\n",
    "\n",
    "test_metrics = {\n",
    "    'type': 'metrics',\n",
    "    'dataset': 'test',\n",
    "    'precision': precision_score(y_test, y_test_pred),\n",
    "    'balanced_accuracy': balanced_accuracy_score(y_test, y_test_pred),\n",
    "    'recall': recall_score(y_test, y_test_pred),\n",
    "    'f1_score': f1_score(y_test, y_test_pred)\n",
    "}\n",
    "# Calcular las matrices de confusión\n",
    "train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Convertir las matrices de confusión a diccionarios y asegurarse de que los valores sean int\n",
    "train_cm_dict = {\n",
    "    'type': 'cm_matrix',\n",
    "    'dataset': 'train',\n",
    "    'true_0': {'predicted_0': int(train_cm[0, 0]), 'predicted_1': int(train_cm[0, 1])},\n",
    "    'true_1': {'predicted_0': int(train_cm[1, 0]), 'predicted_1': int(train_cm[1, 1])}\n",
    "}\n",
    "\n",
    "test_cm_dict = {\n",
    "    'type': 'cm_matrix',\n",
    "    'dataset': 'test',\n",
    "    'true_0': {'predicted_0': int(test_cm[0, 0]), 'predicted_1': int(test_cm[0, 1])},\n",
    "    'true_1': {'predicted_0': int(test_cm[1, 0]), 'predicted_1': int(test_cm[1, 1])}\n",
    "}\n",
    "\n",
    "with open(\"../files/output/metrics.json\", \"w\") as f:\n",
    "    json.dump([train_metrics, test_metrics, train_cm_dict, test_cm_dict], f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo JSON\n",
    "output_file = '../files/output/metrics.json'\n",
    "\n",
    "# Crear la carpeta si no existe\n",
    "output_dir = os.path.dirname(output_file)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Leer el contenido actual del archivo JSON (si existe)\n",
    "if os.path.exists(output_file) and os.path.getsize(output_file) > 0:\n",
    "    with open(output_file, 'r') as f:\n",
    "        try:\n",
    "            data = json.load(f)  # Cargar el contenido del archivo como una lista\n",
    "        except json.JSONDecodeError:\n",
    "            # Si el archivo está corrupto o vacío, inicializar una lista vacía\n",
    "            data = []\n",
    "else:\n",
    "    data = []\n",
    "\n",
    "# Agregar los nuevos datos a la lista\n",
    "data.append(train_cm_dict)\n",
    "data.append(test_cm_dict)\n",
    "\n",
    "# Escribir el archivo JSON completo\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'metrics',\n",
       "  'dataset': 'train',\n",
       "  'precision': 0.9931614939505523,\n",
       "  'balanced_accuracy': 0.8986087888414297,\n",
       "  'recall': 0.7988153162682462,\n",
       "  'f1_score': 0.8854496423965295},\n",
       " {'type': 'metrics',\n",
       "  'dataset': 'test',\n",
       "  'precision': 0.6681146828844483,\n",
       "  'balanced_accuracy': 0.6744788009561253,\n",
       "  'recall': 0.4028287061288633,\n",
       "  'f1_score': 0.5026143790849673},\n",
       " {'type': 'cm_matrix',\n",
       "  'dataset': 'train',\n",
       "  'true_0': {'predicted_0': 16247, 'predicted_1': 26},\n",
       "  'true_1': {'predicted_0': 951, 'predicted_1': 3776}},\n",
       " {'type': 'cm_matrix',\n",
       "  'dataset': 'test',\n",
       "  'true_0': {'predicted_0': 6709, 'predicted_1': 382},\n",
       "  'true_1': {'predicted_0': 1140, 'predicted_1': 769}}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _load_metrics():\n",
    "    with open(\"../files/output/metrics.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data = file.read().strip()  # Elimina espacios en blanco y saltos de línea al inicio y final\n",
    "        return json.loads(data)\n",
    "\n",
    "data = _load_metrics()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../files/output/metrics.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
